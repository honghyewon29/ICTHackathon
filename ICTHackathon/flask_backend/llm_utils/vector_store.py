from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from config import LANGCHAIN_API_KEY

import os

persist_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../LLM/chroma_db"))

embeddings_model = OpenAIEmbeddings(
    model="text-embedding-3-small",
    api_key=LANGCHAIN_API_KEY
)

vectorstore = None

def initialize_vectorstore(split_docs):
    global vectorstore

    if not split_docs or len(split_docs) == 0:
        raise ValueError("âŒ ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: split_docsê°€ ë¹„ì–´ ìˆìŒ")

    print(f"ğŸ’¾ ë²¡í„°í™”í•  ë¬¸ì„œ ìˆ˜: {len(split_docs)}")
    
    try:
        vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=embeddings_model,
            collection_name="ict_documents",
            persist_directory=persist_dir,
            collection_metadata={"hnsw:space": "ip"}
        )
        vectorstore.persist()
        print(f"âœ… ë²¡í„° ì €ì¥ ì™„ë£Œ! ê²½ë¡œ: {persist_dir}")
    except Exception as e:
        print("âŒ ë²¡í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", str(e))
        raise


def load_vectorstore():
    global vectorstore

    if vectorstore is None:
        print(f"ğŸ“¦ ì €ì¥ëœ ë²¡í„° DB ë¶ˆëŸ¬ì˜¤ê¸°: {persist_dir}")
        vectorstore = Chroma(
            embedding_function=embeddings_model,
            collection_name="ict_documents",
            persist_directory=persist_dir,
        )
    return vectorstore
