import os
from glob import glob
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings


def load_and_split_documents():
    txt_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../LLM/Data"))
    print("ğŸ“‚ ë¶ˆëŸ¬ì˜¤ëŠ” í´ë”:", txt_dir)

    txt_files = glob(os.path.join(txt_dir, "*.txt"))
    print("ğŸ“„ ì°¾ì€ íŒŒì¼ ê°œìˆ˜:", len(txt_files))

    docs = []
    for path in txt_files:
        print("ğŸ“„ ë¡œë“œ ì¤‘:", path)
        loader = TextLoader(path, encoding="utf-8")
        docs.extend(loader.load())

    print("ğŸ“„ ë¡œë”© ì™„ë£Œ, ë¬¸ì„œ ìˆ˜:", len(docs))

    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ".", "!", "?", " ", ""],
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
        is_separator_regex=True
    )

    chunks = text_splitter.split_documents(docs)
    print("ğŸ§© ë¶„í• ëœ ì²­í¬ ìˆ˜:", len(chunks))

    return chunks

# embedding.py
from langchain_huggingface import HuggingFaceEmbeddings

# âœ… ì•± ì‹œì‘ ì‹œ ë‹¨ í•œ ë²ˆë§Œ ë¡œë”©ë¨
print("ğŸ§  í•œêµ­ì–´ íŠ¹í™” KoSimCSE ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
embedding_model = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-nli")

def get_korean_embedding_model():
    return embedding_model
