# rag_service.py
from llm_utils.vector_store import load_vectorstore
from llm_utils.prompt_template import get_prompt
from llm_utils.gpt_client import generate_response
from llm_utils.retriever import get_multiquery_retriever
from llm_utils.normalizer import normalize_question

context_boilerplate = """
ì´ ì±—ë´‡ì€ ìˆ˜ì›ëŒ€í•™êµì˜ ì§€ëŠ¥í˜•SWìœµí•©ëŒ€í•™ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•©ë‹ˆë‹¤.

ì§€ëŠ¥í˜•SWìœµí•©ëŒ€í•™ì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
- ì»´í“¨í„°í•™ë¶€ â†’ ì»´í“¨í„°SWí•™ê³¼, ë¯¸ë””ì–´SWí•™ê³¼
- ì •ë³´í†µì‹ í•™ë¶€ â†’ ì •ë³´í†µì‹ í•™ê³¼, ì •ë³´ë³´í˜¸í•™ê³¼
- ë°ì´í„°ê³¼í•™ë¶€ (ë‹¨ì¼)
- í´ë¼ìš°ë“œìœµë³µí•©ì „ê³µ (ë‹¨ì¼)
ì¦‰, "ì»´í“¨í„°SWí•™ê³¼"ëŠ” "ì»´í“¨í„°í•™ë¶€"ì— í¬í•¨ë©ë‹ˆë‹¤.

ì»´í“¨í„°sw í•™ê³¼ êµìˆ˜ì§„ ì •ë³´

ì¥ì„±íƒœ êµìˆ˜ëŠ” ì»´í“¨í„°SWí•™ê³¼ ì†Œì†ìœ¼ë¡œ, ì „ê³µì€ ì»´í“¨í„°êµ¬ì¡°, ì°¨ì„¸ëŒ€ Mobile Embedded System, ë³´ì•ˆê°ì‹œ ê¸°ìˆ ì´ë©°, ì´ë©”ì¼ì€ stjhang@suwon.ac.kr, ì—°êµ¬ì‹¤ì€ ICT ìœµí•©ëŒ€í•™ 510í˜¸, ì—°ë½ì²˜ëŠ” 031-220-2126ì…ë‹ˆë‹¤.

í•œì„±ì¼ êµìˆ˜ëŠ” ì»´í“¨í„°SWí•™ê³¼ ì†Œì†ì´ë©°, ì „ê³µì€ Applied Machine Learningì…ë‹ˆë‹¤. ì´ë©”ì¼ì€ seongil.han@suwon.ac.kr, ì—°êµ¬ì‹¤ì€ ICT ìœµí•©ëŒ€í•™ 521í˜¸, ì—°ë½ì²˜ëŠ” 031-229-8218ì…ë‹ˆë‹¤.

ì¤€ì›¨ì´í‘¸ êµìˆ˜ëŠ” ì»´í“¨í„°SWí•™ê³¼ ì†Œì†ì´ë©°, ì „ê³µê³¼ ì—°ë½ì²˜ ì •ë³´ëŠ” ì—†ìœ¼ë©°, ì´ë©”ì¼ë„ ì—†ìŠµë‹ˆë‹¤. ì—°êµ¬ì‹¤ì€ ITëŒ€í•™ 405í˜¸ì…ë‹ˆë‹¤.

ê¹€ì¥ì˜ êµìˆ˜ëŠ” ì»´í“¨í„°SWí•™ê³¼ ì†Œì†ì´ë©°, ì „ê³µì€ ë¹…ë°ì´í„°, ë„¤íŠ¸ì›Œí¬, ì¸ê³µì§€ëŠ¥, ë³´ì•ˆì…ë‹ˆë‹¤. ì´ë©”ì¼ì€ jykim77@suwon.ac.kr, ì—°êµ¬ì‹¤ì€ ì§€ëŠ¥í˜•SWìœµí•©ëŒ€í•™ 522í˜¸, ì—°ë½ì²˜ëŠ” 031-229-8345ì…ë‹ˆë‹¤.

êµ¬ì°½ì§„ êµìˆ˜ëŠ” ì»´í“¨í„°SWí•™ê³¼ ì†Œì†ì´ë©°, ì „ê³µì€ ìš´ì˜ì²´ì œì™€ ì •ë³´ë³´í˜¸ì…ë‹ˆë‹¤. ì´ë©”ì¼ì€ ycjkoo@suwon.ac.kr, ì—°êµ¬ì‹¤ì€ ë¯¸ë˜í˜ì‹ ê´€ 712í˜¸, ì—°ë½ì²˜ëŠ” 031-229-8595ì…ë‹ˆë‹¤.

í—ˆì„±ë¯¼ êµìˆ˜ëŠ” ì»´í“¨í„°SWí•™ê³¼ ì†Œì†ì´ë©°, ì „ê³µ, ì´ë©”ì¼, ì—°êµ¬ì‹¤, ì—°ë½ì²˜ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.


í•˜ê³„ë°©í•™ì€ 1í•™ê¸° ì¢…ê°• í›„ ì‹œì‘ë˜ë©°, ë™ê³„ë°©í•™ì€ 2í•™ê¸° ì¢…ê°• í›„ ì‹œì‘ë©ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì…”í‹€ë²„ìŠ¤ì— ëŒ€í•œ ë‚´ìš©ì´ë©´, ì…”í‹€ë²„ìŠ¤ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
ì…”í‹€ì´ ì•„ë‹Œ ëŒ€ì¤‘êµí†µ(ì‹œë‚´/ê´‘ì—­/ë§ˆì„ë²„ìŠ¤ ë“±) ê´€ë ¨ì´ë©´, ëŒ€ì¤‘êµí†µ ë²„ìŠ¤ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
ì–´ë–¤ ì¢…ë¥˜ì¸ì§€ êµ¬ë¶„ì´ ì–´ë µë‹¤ë©´, ë¨¼ì € ì–´ë–¤ ì •ë³´ë¥¼ ì›í•˜ëŠ”ì§€ ë¬¼ì–´ë³´ì„¸ìš”.
s
"""



def format_docs_with_boilerplate(docs):
    context_from_docs = "\n\n".join([d.page_content for d in docs])
    return context_boilerplate + "\n\n" + context_from_docs

def ask_with_rag(user_input):
    # 1. ì •í˜•í™” (ê²€ìƒ‰ ìµœì í™”ìš©)
    normalized = normalize_question(user_input)
    print(f"ğŸ“Œ ì •í˜•í™”ëœ ì§ˆë¬¸: {normalized}")

    # 2. ë²¡í„°ìŠ¤í† ì–´ + ê²€ìƒ‰
    vectorstore = load_vectorstore()
    retriever = get_multiquery_retriever(vectorstore)
    retrieved_docs = retriever.invoke(normalized)
    print("ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜:", len(retrieved_docs))
    print("ê²€ìƒ‰ëœ ë¬¸ì„œ:", retrieved_docs)

    # 3. ë¬¸ì„œ ë‚´ìš© í¬ë§·
    full_context = format_docs_with_boilerplate(retrieved_docs)

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (â—ì§ˆë¬¸ì€ ì›ë˜ ì§ˆë¬¸ ì‚¬ìš©)
    prompt = get_prompt()
    messages = prompt.format_messages(context=full_context, question=user_input)
    print("ğŸ§± ìµœì¢… prompt ë‚´ìš©:", messages)

    # 5. ì‘ë‹µ ìƒì„±
    response = generate_response(messages)
    print("ğŸ’¬ messages:", user_input)
    return response.content.strip()
